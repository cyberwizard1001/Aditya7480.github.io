<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Model Prediction</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <style>
        body {
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            min-height: 100vh;
            margin: 0;
            font-family: Arial, sans-serif;
        }
        video {
            max-width: 90%;
            border-radius: 15px; /* Rounded corners */
            box-shadow: 0 4px 8px rgba(0,0,0,0.2);
        }
        button {
            margin: 20px 0;
            padding: 10px 20px;
            font-size: 16px;
            cursor: pointer;
            border: none;
            border-radius: 5px;
            background-color: #007bff;
            color: white;
        }
        p {
            font-size: 18px;
            color: #333;
        }
    </style>
</head>
<body>

<h2>Identify Food</h2>

<video id="video" autoplay playsinline></video>
<!--<button onclick="switchCamera()">Switch Camera</button>-->
<p id="result"></p>

<script>
    ////////////////////////////////
    ////////    SPECIFY PARAMETERS
    ////////////////////////////////
    const PROCESSING_SPEED = 2000;
    const CLASSES = ["Potato",
        "Potato | Value per 100g | Cal - 161 | Carbohydrates - 37g | Fat - 0.2g | Protein - 4.3g",
        "Apple",
        "Apple | Value per 100g | Cal - 95 | carbohydrates - 25g | Fat -0.3g |  Protein - 0.5g",
        "Orange",
        "Orange | Value per 100g | Cal - 47 | Carbohydrates - 11.7g | Fat - 0.1g |  Protein- 0.9g",
        "Onions",
        "Onion | Value per 100g | Cal - 44 | Carbohydrates - 10g | Fat - 0.2g |  Protein- 1.4g",
        "Carrot",
        "Carrot | Value per 100g | Cal - 35 | Carbohydrates - 8.2g | Fat - 0.2g |  Protein- 0.8g",
        "Extra",
        "Watermelon",
        "Watermelon | Value per 100g | Cal - 30 | Carbohydrates - 7.6g | Fat - 0.2g |  Protein- 0.6g",
        "Strawberry",
        "Strawberry | Value per 100g | Cal - 32 | Carbohydrates - 7.7g | Fat - 0.3g |  Protein - 0.7g",
        "Broccoli",
        "Broccoli | Value per 100g | Cal - 35 | Carbohydrates - 7.3g | Fat - 0.4g |  Protein - 2.4g",
        "Bell pepper",
        "Bell pepper | Value per 100g | Cal - 28 | Carbohydrates - 6.6g | Fat - 0.2g |  Protein - 1g",
        "Banana",
        "Banana | Value per 100g | Cal - 89 | Carbohydrates - 23g | Fat - 0.3g |  Protein - 1.1g",
    ];
    const MODEL_FOLDER = 'model/model.json';
    // const mode = 'environment' // back camera
    const camera_mode = 'user' // front camera

    let currentStream;

    ////////////////////////////////
    ////////    USE THIS FUNCTION FOR INTERACTIONS
    ////////////////////////////////
    function interaction(predictedClass, classScores) {
        console.log(classScores);
        document.getElementById("result").innerHTML = `Prediction: ${predictedClass}, Confidence: ${classScores[0]}`;
        document.body.style.backgroundColor = predictedClass === "hat" ? "red" : "white";
    }

    ////////////////////////////////
    ////////    VIDEO CAPTURE AND PREDICTION LOGIC
    ////////////////////////////////
    async function startVideo(facingMode = 'user') {
        // Stop any existing video tracks to free up the camera
        if (currentStream) {
            currentStream.getTracks().forEach(track => {
                track.stop();
            });
        }

        try {
            // Request access to the camera with the specified facing mode
            const stream = await navigator.mediaDevices.getUserMedia({
                video: { facingMode }
            });

            const videoElement = document.getElementById('video');
            videoElement.srcObject = stream;
            currentStream = stream;

            // Return a promise that resolves when the video is ready to play
            return new Promise(resolve => {
                videoElement.onloadedmetadata = () => {
                    resolve(videoElement);
                };
            });
        } catch (err) {
            console.error('Error accessing the camera:', err);
        }
    }


    async function startPredicting() {
        const model = await tf.loadGraphModel(MODEL_FOLDER);
        setInterval(async () => {
            const example = tf.browser.fromPixels(video).cast('float32');
            const prediction = await model.predict(example.expandDims());
            const classScores = await prediction.data();
            const maxScoreId = classScores.indexOf(Math.max(...classScores));
            const predictedClass = CLASSES[maxScoreId];

            interaction(predictedClass, classScores);
        }, PROCESSING_SPEED);
    }

    // function switchCamera() {
    //     if (currentStream) {
    //         currentStream.getTracks().forEach(track => track.stop());
    //     }
    //     startVideo('user');
    // }

    document.addEventListener("DOMContentLoaded", function() {
        startVideo(camera_mode);
        startPredicting();
    });
</script>
</body>
</html>
